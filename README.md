# ğŸ§  AI Multi-Agent Article Generator  
### FastAPI â€¢ CrewAI â€¢ Streamlit â€¢ Ollama (Local LLM)

An end-to-end AI content generation system powered by a multi-agent pipeline using CrewAI.  
The system runs entirely on **free, local LLMs using Ollama**, and provides a production-style backend (FastAPI) and a clean frontend (Streamlit).

---

## ğŸš€ Features

- **Multi-Agent Pipeline**
  - Research Agent  
  - Analysis Agent  
  - Writing Agent  
  - Quality Check Agent  

- **FastAPI Backend**
  - `/run` to generate articles  
  - `/download/<filename>` to retrieve generated files  
  - Clean JSON response  
  - Topic-based filenames  

- **Streamlit Frontend**
  - Text input for topic  
  - Step-by-step agent output in tabs  
  - Downloadable Markdown files  
  - Connects seamlessly with FastAPI  

- **Local LLM via Ollama**
  - Runs Qwen 2.5 7B locally  
  - Fully offline  
  - Zero API cost  

---

## ğŸ§  Tech Stack

- Python  
- FastAPI  
- CrewAI  
- Streamlit  
- Ollama  
- Uvicorn  

---

## ğŸ“¦ Installation

### 1. Clone the repository
git clone https://github.com/FarhanIbrahim03/ai-multi-agent-article-generator.git
cd ai-multi-agent-article-generator


### 2. Create & activate virtual environment
python -m venv venv
venv\Scripts\activate # Windows
source venv/bin/activate # Mac/Linux

### 3. Install dependencies
pip install -r requirements.txt

### 4. Install Ollama
Download: https://ollama.com/download  
Pull model: ollama pull qwen2.5:7b


## ğŸš€ Running the App

### 1. Start FastAPI backend
uvicorn main:app --reload
API docs:
http://localhost:8000/docs

### 2. Start Streamlit frontend
Open a second terminal:
streamlit run frontend.py
UI:
http://localhost:8501

---

## ğŸ“‚ Project Structure
.
â”œâ”€â”€ agents.py # Multi-agent definitions
â”œâ”€â”€ tasks.py # Task descriptions for each agent
â”œâ”€â”€ crew.py # CrewAI pipeline
â”œâ”€â”€ main.py # FastAPI backend
â”œâ”€â”€ frontend.py # Streamlit UI
â”œâ”€â”€ outputs/ # Generated markdown files
â””â”€â”€ requirements.txt


---

## ğŸ“„ How It Works

1. User enters a topic in Streamlit  
2. Frontend sends request â†’ FastAPI `/run`  
3. CrewAI agents execute:
   - Research  
   - Analysis  
   - Writing  
   - Quality Check  
4. Final article saved as markdown in `outputs/`  
5. Streamlit displays results + provides download link  

---

## ğŸ›  Future Enhancements

- PDF output  
- Writing tone/style options  
- Step-by-step visual progress  
- Deployment on Render/Railway  
- Improved UI styling  

---

## ğŸ‘¨â€ğŸ’» Author  
**Farhan Ibrahim**  
AI/ML Developer  
GitHub: https://github.com/FarhanIbrahim03  
LinkedIn: https://www.linkedin.com/in/  

---

